relationships:
  success: {en: All files retrieved from HDFS are transferred to this relationship,
    zh: 从HDFS检索的所有文件都将传输到此关系}
capabilityDescription: {en: Fetch files from Hadoop Distributed File System (HDFS)
    into FlowFiles. This Processor will delete the file from HDFS after fetching it.,
  zh: 将Hadoop分布式文件系统（HDFS）中的文件提取到FlowFiles中。此处理器将在获取文件后从HDFS中删除该文件。}
properties:
  Keep Source File:
    en: {displayName: Keep Source File, description: 'Determines whether to delete
        the file from HDFS after it has been successfully transferred. If true, the
        file will be fetched repeatedly. This is intended for testing only.'}
    zh: {description: 确定成功传输文件后是否从HDFS中删除该文件。如果为true，将重复提取文件。这仅用于测试。, displayName: 保留源文件}
  Hadoop Configuration Resources:
    en: {displayName: Hadoop Configuration Resources, description: 'A file or comma
        separated list of files which contains the Hadoop file system configuration.
        Without this, Hadoop will search the classpath for a ''core-site.xml'' and
        ''hdfs-site.xml'' file or will revert to a default configuration. To use swebhdfs,
        see ''Additional Details'' section of PutHDFS''s documentation.'}
    zh: {description: 包含Hadoop文件系统配置的文件或逗号分隔的文件列表。否则，Hadoop将在类路径中搜索“核心站点”。xml'和'hdfs站点。xml文件，或将恢复为默认配置。要使用swebhdfs，请参阅PutHDFS文档的“其他详细信息”部分。,
      displayName: Hadoop配置资源}
  File Filter Regex:
    en: {displayName: File Filter Regex, description: 'A Java Regular Expression for
        filtering Filenames; if a filter is supplied then only files whose names match
        that Regular Expression will be fetched, otherwise all files will be fetched'}
    zh: {description: 用于过滤文件名的Java正则表达式；如果提供了筛选器，则只提取名称与该正则表达式匹配的文件，否则将提取所有文件, displayName: 文件筛选器Regex}
  Minimum File Age:
    en: {displayName: Minimum File Age, description: The minimum age that a file must
        be in order to be pulled; any file younger than this amount of time (based
        on last modification date) will be ignored}
    zh: {description: 文件必须达到的最短使用期限才能被提取；任何小于此时间（基于上次修改日期）的文件都将被忽略, displayName: 最小文件期限}
  Filter Match Name Only:
    en: {displayName: Filter Match Name Only, description: 'If true then File Filter
        Regex will match on just the filename, otherwise subdirectory names will be
        included with filename in the regex comparison'}
    zh: {description: 如果为true，则File Filter Regex将仅匹配文件名，否则子目录名将与Regex比较中的文件名一起包含,
      displayName: 仅筛选器匹配名称}
  Polling Interval:
    en: {displayName: Polling Interval, description: Indicates how long to wait between
        performing directory listings}
    zh: {description: 指示执行目录列表之间的等待时间, displayName: 轮询间隔}
  Ignore Dotted Files:
    en: {displayName: Ignore Dotted Files, description: 'If true, files whose names
        begin with a dot (".") will be ignored'}
    zh: {description: 如果为true，则将忽略名称以点（“.”）开头的文件, displayName: 忽略点式文件}
  Maximum File Age:
    en: {displayName: Maximum File Age, description: The maximum age that a file must
        be in order to be pulled; any file older than this amount of time (based on
        last modification date) will be ignored}
    zh: {description: 文件必须达到的最长使用期限才能被提取；任何早于此时间（基于上次修改日期）的文件都将被忽略, displayName: 最大文件期限}
  Additional Classpath Resources:
    en: {displayName: Additional Classpath Resources, description: 'A comma-separated
        list of paths to files and/or directories that will be added to the classpath
        and used for loading native libraries. When specifying a directory, all files
        with in the directory will be added to the classpath, but further sub-directories
        will not be included.'}
    zh: {description: 以逗号分隔的文件和/或目录路径列表，这些路径将添加到类路径中并用于加载本机库。指定目录时，目录中的所有文件都将添加到类路径中，但不包括其他子目录。,
      displayName: 其他Classpath资源}
  Compression codec:
    en: {displayName: Compression codec, description: ''}
    zh: {description: '', displayName: 压缩编解码器}
  IO Buffer Size:
    en: {displayName: IO Buffer Size, description: Amount of memory to use to buffer
        file contents during IO. This overrides the Hadoop Configuration}
    zh: {description: IO期间用于缓冲文件内容的内存量。这将覆盖Hadoop配置, displayName: IO缓冲区大小}
  Recurse Subdirectories:
    en: {displayName: Recurse Subdirectories, description: Indicates whether to pull
        files from subdirectories of the HDFS directory}
    zh: {description: 指示是否从HDFS目录的子目录中提取文件, displayName: 定期子目录}
  kerberos-credentials-service:
    en: {displayName: Kerberos Credentials Service, description: Specifies the Kerberos
        Credentials Controller Service that should be used for authenticating with
        Kerberos}
    zh: {description: 指定应用于Kerberos身份验证的Kerberos凭据控制器服务, displayName: Kerberos凭据服务}
  Kerberos Password:
    en: {displayName: Kerberos Password, description: Kerberos password associated
        with the principal.}
    zh: {description: 与主体关联的Kerberos密码。, displayName: Kerberos密码}
  Kerberos Keytab:
    en: {displayName: Kerberos Keytab, description: Kerberos keytab associated with
        the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties}
    zh: {description: 与主体关联的Kerberos密钥表。需要在nifi.properties中设置nifi.krberos.krb5.file,
      displayName: Kerberos密钥选项卡}
  Batch Size:
    en: {displayName: Batch Size, description: 'The maximum number of files to pull
        in each iteration, based on run schedule.'}
    zh: {description: 基于运行计划，每次迭代中要提取的最大文件数。, displayName: 批量大小}
  Kerberos Principal:
    en: {displayName: Kerberos Principal, description: Kerberos principal to authenticate
        as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties}
    zh: {description: 要作为身份验证的Kerberos主体。需要在nifi.properties中设置nifi.krberos.krb5.file,
      displayName: Kerberos主体}
  kerberos-user-service:
    en: {displayName: Kerberos User Service, description: Specifies the Kerberos User
        Controller Service that should be used for authenticating with Kerberos}
    zh: {description: 指定应用于Kerberos身份验证的Kerberos用户控制器服务, displayName: Kerberos用户服务}
  Kerberos Relogin Period:
    en:
      displayName: Kerberos Relogin Period
      description: |-
        Period of time which should pass before attempting a kerberos relogin.

        This property has been deprecated, and has no effect on processing. Relogins now occur automatically.
    zh: {description: 在尝试kerberos重新登录之前应该经过的时间段。, displayName: Kerberos时钟周期}
  Directory:
    en: {displayName: Directory, description: The HDFS directory from which files
        should be read}
    zh: {description: 应从中读取文件的HDFS目录, displayName: 目录}
writeAttributes:
  path: {en: 'The path is set to the relative path of the file''s directory on HDFS.
      For example, if the Directory property is set to /tmp, then files picked up
      from /tmp will have the path attribute set to "./". If the Recurse Subdirectories
      property is set to true and a file is picked up from /tmp/abc/1/2/3, then the
      path attribute will be set to "abc/1/2/3".', zh: 路径设置为HDFS上文件目录的相对路径。例如，如果Directory属性设置为/tmp，则从/tmp拾取的文件的路径属性将设置为“./”。如果Recurse
      Subdirectories属性设置为true，并且从/tmp/abc/1/2/3获取文件，则路径属性将设置为“abc/1/2/3”。}
  filename: {en: The name of the file that was read from HDFS., zh: 从HDFS读取的文件的名称。}
tags:
  en: [hadoop, HCFS, HDFS, get, fetch, ingest, source, filesystem]
  zh: [hadoop公司, 人类基因组学, 高密度光纤, 收到, 取来, 摄入, 来源, 文件系统]
