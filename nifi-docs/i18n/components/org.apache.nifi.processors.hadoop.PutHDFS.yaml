relationships:
  success: {en: Files that have been successfully written to HDFS are transferred
      to this relationship, zh: 已成功写入HDFS的文件将传输到此关系}
  failure: {en: Files that could not be written to HDFS for some reason are transferred
      to this relationship, zh: 由于某些原因无法写入HDFS的文件将传输到此关系}
capabilityDescription: {en: Write FlowFile data to Hadoop Distributed File System
    (HDFS), zh: 将FlowFile数据写入Hadoop分布式文件系统（HDFS）}
readAttributes:
  filename: {en: The name of the file written to HDFS comes from the value of this
      attribute., zh: 写入HDFS的文件名来自此属性的值。}
properties:
  Permissions umask:
    en: {displayName: Permissions umask, description: 'A umask represented as an octal
        number which determines the permissions of files written to HDFS. This overrides
        the Hadoop property "fs.permissions.umask-mode".  If this property and "fs.permissions.umask-mode"
        are undefined, the Hadoop default "022" will be used.  If the PutHDFS target
        folder has a default ACL defined, the umask property is ignored by HDFS.'}
    zh: {description: 表示为八进制数的umask，用于确定写入HDFS的文件的权限。这将覆盖Hadoop属性“fs.permissions.umask模式”。如果未定义此属性和“fs.ppermissions.umask模式”，将使用Hadoop默认值“022”。如果PutHDFS目标文件夹定义了默认ACL，HDFS将忽略umask属性。,
      displayName: 权限umask}
  Hadoop Configuration Resources:
    en: {displayName: Hadoop Configuration Resources, description: 'A file or comma
        separated list of files which contains the Hadoop file system configuration.
        Without this, Hadoop will search the classpath for a ''core-site.xml'' and
        ''hdfs-site.xml'' file or will revert to a default configuration. To use swebhdfs,
        see ''Additional Details'' section of PutHDFS''s documentation.'}
    zh: {description: 包含Hadoop文件系统配置的文件或逗号分隔的文件列表。否则，Hadoop将在类路径中搜索“核心站点”。xml'和'hdfs站点。xml文件，或将恢复为默认配置。要使用swebhdfs，请参阅PutHDFS文档的“其他详细信息”部分。,
      displayName: Hadoop配置资源}
  Remote Owner:
    en: {displayName: Remote Owner, description: Changes the owner of the HDFS file
        to this value after it is written. This only works if NiFi is running as a
        user that has HDFS super user privilege to change owner}
    zh: {description: 写入HDFS文件后，将其所有者更改为该值。只有当NiFi以具有HDFS超级用户权限的用户身份运行时，才能更改所有者, displayName: 远程所有者}
  Additional Classpath Resources:
    en: {displayName: Additional Classpath Resources, description: 'A comma-separated
        list of paths to files and/or directories that will be added to the classpath
        and used for loading native libraries. When specifying a directory, all files
        with in the directory will be added to the classpath, but further sub-directories
        will not be included.'}
    zh: {description: 以逗号分隔的文件和/或目录路径列表，这些路径将添加到类路径中并用于加载本机库。指定目录时，目录中的所有文件都将添加到类路径中，但不包括其他子目录。,
      displayName: 其他Classpath资源}
  Compression codec:
    en: {displayName: Compression codec, description: ''}
    zh: {description: '', displayName: 压缩编解码器}
  IO Buffer Size:
    en: {displayName: IO Buffer Size, description: Amount of memory to use to buffer
        file contents during IO. This overrides the Hadoop Configuration}
    zh: {description: IO期间用于缓冲文件内容的内存量。这将覆盖Hadoop配置, displayName: IO缓冲区大小}
  Remote Group:
    en: {displayName: Remote Group, description: Changes the group of the HDFS file
        to this value after it is written. This only works if NiFi is running as a
        user that has HDFS super user privilege to change group}
    zh: {description: 写入HDFS文件后，将其组更改为该值。只有当NiFi以具有HDFS超级用户权限的用户身份运行时，才能更改组, displayName: 远程组}
  Block Size:
    en: {displayName: Block Size, description: Size of each block as written to HDFS.
        This overrides the Hadoop Configuration}
    zh: {description: 写入HDFS的每个块的大小。这将覆盖Hadoop配置, displayName: 块大小（Block Size）}
  kerberos-credentials-service:
    en: {displayName: Kerberos Credentials Service, description: Specifies the Kerberos
        Credentials Controller Service that should be used for authenticating with
        Kerberos}
    zh: {description: 指定应用于Kerberos身份验证的Kerberos凭据控制器服务, displayName: Kerberos凭据服务}
  Kerberos Password:
    en: {displayName: Kerberos Password, description: Kerberos password associated
        with the principal.}
    zh: {description: 与主体关联的Kerberos密码。, displayName: Kerberos密码}
  Kerberos Keytab:
    en: {displayName: Kerberos Keytab, description: Kerberos keytab associated with
        the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties}
    zh: {description: 与主体关联的Kerberos密钥表。需要在nifi.properties中设置nifi.krberos.krb5.file,
      displayName: Kerberos密钥选项卡}
  Ignore Locality:
    en: {displayName: Ignore Locality, description: Directs the HDFS system to ignore
        locality rules so that data is distributed randomly throughout the cluster}
    zh: {description: 指示HDFS系统忽略位置规则，以便数据在整个集群中随机分布, displayName: 忽略位置}
  Kerberos Principal:
    en: {displayName: Kerberos Principal, description: Kerberos principal to authenticate
        as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties}
    zh: {description: 要作为身份验证的Kerberos主体。需要在nifi.properties中设置nifi.krberos.krb5.file,
      displayName: Kerberos主体}
  Replication:
    en: {displayName: Replication, description: Number of times that HDFS will replicate
        each file. This overrides the Hadoop Configuration}
    zh: {description: HDFS将复制每个文件的次数。这将覆盖Hadoop配置, displayName: 复制}
  kerberos-user-service:
    en: {displayName: Kerberos User Service, description: Specifies the Kerberos User
        Controller Service that should be used for authenticating with Kerberos}
    zh: {description: 指定应用于Kerberos身份验证的Kerberos用户控制器服务, displayName: Kerberos用户服务}
  writing-strategy:
    en: {displayName: Writing Strategy, description: Defines the approach for writing
        the FlowFile data.}
    zh: {description: 定义写入FlowFile数据的方法。, displayName: 写作策略}
  Kerberos Relogin Period:
    en:
      displayName: Kerberos Relogin Period
      description: |-
        Period of time which should pass before attempting a kerberos relogin.

        This property has been deprecated, and has no effect on processing. Relogins now occur automatically.
    zh: {description: 在尝试kerberos重新登录之前应该经过的时间段。, displayName: Kerberos时钟周期}
  Directory:
    en: {displayName: Directory, description: The parent HDFS directory to which files
        should be written. The directory will be created if it doesn't exist.}
    zh: {description: 文件应写入的父HDFS目录。如果目录不存在，将创建该目录。, displayName: 目录}
  Conflict Resolution Strategy:
    en: {displayName: Conflict Resolution Strategy, description: Indicates what should
        happen when a file with the same name already exists in the output directory}
    zh: {description: 指示当输出目录中已存在同名文件时应执行的操作, displayName: 冲突解决策略}
writeAttributes:
  filename: {en: The name of the file written to HDFS is stored in this attribute.,
    zh: 写入HDFS的文件名存储在此属性中。}
  target.dir.created: {en: The result(true/false) indicates if the folder is created
      by the processor., zh: 结果（真/假）表示文件夹是否由处理器创建。}
  absolute.hdfs.path: {en: The absolute path to the file on HDFS is stored in this
      attribute., zh: HDFS上文件的绝对路径存储在此属性中。}
tags:
  en: [hadoop, HCFS, HDFS, put, copy, filesystem]
  zh: [hadoop公司, 人类基因组学, 高密度光纤, 放, 复制, 文件系统]
